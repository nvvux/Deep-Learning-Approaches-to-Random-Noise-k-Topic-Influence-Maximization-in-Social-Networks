{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T11:51:48.555311Z",
     "start_time": "2025-05-25T11:51:47.088139Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "def read_graph(file_path):\n",
    "    \"\"\"\n",
    "    Đọc đồ thị có hướng:\n",
    "    - file có dòng đầu: \"n m\"\n",
    "    - các dòng sau: u v\n",
    "    Trả về: n (số nút), m (số cạnh), list of directed edges [(u,v), ...]\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        n, m = map(int, f.readline().split())\n",
    "        for line in f:\n",
    "            u, v = map(int, line.split())\n",
    "            edges.append((u, v))\n",
    "    return n, m, edges\n",
    "\n",
    "def build_in_adj(edges):\n",
    "    \"\"\"\n",
    "    Từ danh sách (u,v), build dictionary in_adj[v] = [u1, u2, ...]\n",
    "    \"\"\"\n",
    "    in_adj = {}\n",
    "    for u, v in edges:\n",
    "        in_adj.setdefault(v, []).append(u)\n",
    "    return in_adj\n",
    "\n",
    "def gen_normalized_probs(in_adj, k):\n",
    "    \"\"\"\n",
    "    Với mỗi topic t = 0..k-1, và mỗi đích v,\n",
    "    - sinh len(in_adj[v]) số ngẫu nhiên > 0\n",
    "    - chuẩn hóa để sum = 1\n",
    "    Trả về dict probs[(u,v)] = [p_t ...]\n",
    "    \"\"\"\n",
    "    probs = { (u,v): [0.0]*k for v, us in in_adj.items() for u in us }\n",
    "    for t in range(k):\n",
    "        for v, us in in_adj.items():\n",
    "            # sinh raw weights\n",
    "            raw = [random.random() for _ in us]\n",
    "            S = sum(raw)\n",
    "            # nếu S==0 (không có incoming), bỏ qua\n",
    "            if S == 0:\n",
    "                continue\n",
    "            # gán\n",
    "            for u, r in zip(us, raw):\n",
    "                probs[(u,v)][t] = r / S\n",
    "    return probs\n",
    "\n",
    "def save_output(n, m, edges, probs, k, out_path):\n",
    "    \"\"\"\n",
    "    Ghi:\n",
    "      n m\n",
    "      u v p1 p2 ... pk\n",
    "    \"\"\"\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{n} {m}\\n\")\n",
    "        for u, v in edges:\n",
    "            p_list = probs.get((u,v), [0.0]*k)\n",
    "            p_str = \" \".join(f\"{p:.4f}\" for p in p_list)\n",
    "            f.write(f\"{u} {v} {p_str}\\n\")\n",
    "    print(f\"Đã ghi {len(edges)} dòng xác suất vào '{out_path}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file  = \"facebook\"    # file gốc\n",
    "    output_file = \"output.txt\"\n",
    "    k = 10                       # số chủ đề\n",
    "\n",
    "    # 1) đọc graph\n",
    "    n, m, edges = read_graph(input_file)\n",
    "\n",
    "    # 2) build in‐adjacency\n",
    "    in_adj = build_in_adj(edges)\n",
    "\n",
    "    # 3) sinh và chuẩn hoá xác suất\n",
    "    probs = gen_normalized_probs(in_adj, k)\n",
    "\n",
    "    # 4) lưu file\n",
    "    save_output(n, m, edges, probs, k, output_file)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã ghi 176468 dòng xác suất vào 'output.txt'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f4323311b9c03b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T19:31:01.544953Z",
     "start_time": "2025-05-23T19:29:59.699512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/212.5 MB 8.3 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 1.8/212.5 MB 8.4 MB/s eta 0:00:26\n",
      "    --------------------------------------- 3.7/212.5 MB 7.0 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 5.5/212.5 MB 7.8 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 7.3/212.5 MB 8.1 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 9.2/212.5 MB 8.3 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 11.3/212.5 MB 8.5 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 13.1/212.5 MB 8.7 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 15.2/212.5 MB 8.8 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 17.0/212.5 MB 8.9 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 19.1/212.5 MB 9.0 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 21.2/212.5 MB 9.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 23.3/212.5 MB 9.2 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 25.4/212.5 MB 9.3 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 27.5/212.5 MB 9.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 29.6/212.5 MB 9.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 31.7/212.5 MB 9.5 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 33.8/212.5 MB 9.5 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 35.9/212.5 MB 9.6 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 38.0/212.5 MB 9.7 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 40.1/212.5 MB 9.7 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 42.2/212.5 MB 9.7 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 44.3/212.5 MB 9.8 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 46.4/212.5 MB 9.8 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 48.5/212.5 MB 9.8 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 50.6/212.5 MB 9.9 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 53.0/212.5 MB 9.9 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 55.1/212.5 MB 9.9 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 57.1/212.5 MB 9.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 59.2/212.5 MB 10.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 61.3/212.5 MB 10.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 63.4/212.5 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 65.5/212.5 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 67.9/212.5 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 70.0/212.5 MB 10.1 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 72.1/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 74.4/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 76.5/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 78.6/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 81.0/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 83.1/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 85.5/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 87.6/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 89.9/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 92.3/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 94.4/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 96.7/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 99.1/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 101.4/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 103.8/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 106.2/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 108.0/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 109.8/212.5 MB 10.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 111.4/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 113.2/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 115.3/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 117.2/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 119.3/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 121.1/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 123.2/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 125.3/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 127.1/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 129.2/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 131.6/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 133.7/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 136.1/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 138.1/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 140.5/212.5 MB 10.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 142.9/212.5 MB 10.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 145.0/212.5 MB 10.3 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 147.3/212.5 MB 10.4 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 149.7/212.5 MB 10.4 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 152.0/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 154.4/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 156.8/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 158.9/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 160.4/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 162.3/212.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 163.8/212.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 165.7/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 167.5/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 169.3/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 171.2/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 173.0/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 175.1/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 176.9/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 178.8/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 180.9/212.5 MB 10.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 182.7/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 184.8/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 186.6/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 188.7/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 190.8/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 192.7/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 194.8/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 196.9/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 198.7/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 200.8/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 202.9/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 205.0/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 206.8/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  208.9/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  210.8/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 8.9 MB/s eta 0:00:00\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.13.2\n",
      "\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "    Uninstalling sympy-1.13.2:\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ---------------------------------------- 4/4 [torchaudio]\n",
      "\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install networkx torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f170dc8d4000058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T11:52:20.578381Z",
     "start_time": "2025-05-25T11:52:19.480089Z"
    }
   },
   "source": [
    "# load_data.py\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def load_generated_data(file_path):\n",
    "    \"\"\"\n",
    "    Đọc file 'output.txt' do generate_data.py sinh ra:\n",
    "    - Dòng 1: n m\n",
    "    - Dòng i>1: u v p1 p2 … p_k\n",
    "    Trả về:\n",
    "      n, m, k,\n",
    "      edges: list of (u,v),\n",
    "      probs: dict {(u,v): [p1,…,p_k]},\n",
    "      G: networkx.DiGraph với edge attribute 'p' = [p1,…,p_k]\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        header = f.readline().strip().split()\n",
    "        n, m = map(int, header)\n",
    "        lines = f.readlines()\n",
    "\n",
    "    edges = []\n",
    "    probs = {}\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if not parts:\n",
    "            continue\n",
    "        u, v = map(int, parts[:2])\n",
    "        p_list = list(map(float, parts[2:]))\n",
    "        edges.append((u, v))\n",
    "        probs[(u, v)] = p_list\n",
    "\n",
    "    k = len(p_list) if edges else 0\n",
    "\n",
    "    # Xây graph có hướng (vì dùng in-adj lúc sinh)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(n))\n",
    "    for (u, v), p in probs.items():\n",
    "        G.add_edge(u, v, p=p)\n",
    "\n",
    "    return n, m, k, edges, probs, G\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"output.txt\"\n",
    "    n, m, k, edges, probs, G = load_generated_data(file_path)\n",
    "\n",
    "    print(f\"Đã load: n={n}, m={m}, k={k}\")\n",
    "    print(\"5 cạnh đầu và xác suất tương ứng:\")\n",
    "    for (u, v) in edges[:5]:\n",
    "        print(f\"  {u} -> {v} : {probs[(u, v)]}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã load: n=4039, m=176468, k=10\n",
      "5 cạnh đầu và xác suất tương ứng:\n",
      "  0 -> 1 : [0.0851, 0.0771, 0.0832, 0.1346, 0.1298, 0.0178, 0.0957, 0.0683, 0.0176, 0.0974]\n",
      "  0 -> 2 : [0.057, 0.1421, 0.0636, 0.2014, 0.0208, 0.0289, 0.0667, 0.0751, 0.117, 0.1758]\n",
      "  0 -> 3 : [0.0168, 0.0361, 0.0793, 0.0478, 0.1254, 0.0702, 0.0892, 0.0889, 0.069, 0.0719]\n",
      "  0 -> 4 : [0.1939, 0.0613, 0.0195, 0.1145, 0.1521, 0.0861, 0.0739, 0.1384, 0.072, 0.1021]\n",
      "  0 -> 5 : [0.0299, 0.08, 0.1313, 0.1015, 0.1839, 0.1195, 0.0305, 0.1247, 0.0814, 0.1059]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "193f950f8a8b9140",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-25T11:52:26.317578Z"
    }
   },
   "source": [
    "# main.py\n",
    "\n",
    "import random\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. Multi-Topic IC với Gaussian noise clamp in [-0.1,0.1] ---\n",
    "class MultiTopicIC:\n",
    "    def __init__(self,\n",
    "                 G: nx.DiGraph,\n",
    "                 k: int,\n",
    "                 base_prob: Dict[int, Dict[Tuple[int,int], float]],\n",
    "                 sigma: float = 0.05):\n",
    "        self.G = G\n",
    "        self.k = k\n",
    "        self.base_prob = base_prob\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def _noisy_prob(self, t: int, u: int, v: int) -> float:\n",
    "        p0 = self.base_prob[t].get((u, v), 0.0)\n",
    "        noise = random.gauss(0, self.sigma)\n",
    "        # clamp noise vào [-0.1,0.1]\n",
    "        noise = max(min(noise, 0.1), -0.1)\n",
    "        p = p0 + noise\n",
    "        # clamp p vào [0,1]\n",
    "        return float(min(max(p, 0.0), 1.0))\n",
    "\n",
    "    def simulate(self, seeds: List[Set[int]]) -> List[Set[int]]:\n",
    "        activated = [set(S) for S in seeds]\n",
    "        frontier  = [set(S) for S in seeds]\n",
    "        global_active = {v: -1 for v in self.G.nodes()}\n",
    "        for t, S in enumerate(seeds):\n",
    "            for v in S:\n",
    "                global_active[v] = t\n",
    "\n",
    "        while any(frontier):\n",
    "            new_f = [set() for _ in range(self.k)]\n",
    "            for t in range(self.k):\n",
    "                for u in frontier[t]:\n",
    "                    for v in self.G.successors(u):\n",
    "                        if global_active[v] == -1 and random.random() <= self._noisy_prob(t, u, v):\n",
    "                            global_active[v] = t\n",
    "                            new_f[t].add(v)\n",
    "                            activated[t].add(v)\n",
    "            frontier = new_f\n",
    "        return activated\n",
    "\n",
    "    def expected_spread(self, seeds: List[Set[int]], runs: int = 100) -> List[float]:\n",
    "        cum = [0.0]*self.k\n",
    "        for _ in range(runs):\n",
    "            act = self.simulate(seeds)\n",
    "            for t in range(self.k):\n",
    "                cum[t] += len(act[t])\n",
    "        return [x/runs for x in cum]\n",
    "\n",
    "\n",
    "# --- 2. MLP cho dự đoán spread ---\n",
    "class InfluenceMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int = 4, hidden_dims: List[int] = [64, 32, 16]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        # 3 hidden layers: 64, 32, 16\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(prev, h), nn.ReLU()]\n",
    "            prev = h\n",
    "        # output layer\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "# --- 3. Feature extraction (4-dim) ---\n",
    "def extract_feature(\n",
    "    seed_set: Set[int],\n",
    "    degree_centrality: Dict[int, float],\n",
    "    base_prob_topic: Dict[Tuple[int,int], float],\n",
    "    G: nx.DiGraph,\n",
    "    topic: int\n",
    ") -> torch.Tensor:\n",
    "    # 1) |S|\n",
    "    f1 = float(len(seed_set))\n",
    "    # 2) sum degree_centrality\n",
    "    f2 = sum(degree_centrality[v] for v in seed_set)\n",
    "    # 3) sum base_prob cho tất cả (u->w), u in S\n",
    "    sprob = 0.0\n",
    "    for u in seed_set:\n",
    "        for w in G.successors(u):\n",
    "            sprob += base_prob_topic.get((u, w), 0.0)\n",
    "    f3 = sprob\n",
    "    # 4) topic id\n",
    "    f4 = float(topic)\n",
    "    return torch.tensor([f1, f2, f3, f4], dtype=torch.float32)\n",
    "\n",
    "\n",
    "# --- 4. Greedy search giống trước ---\n",
    "def search_optimal_seeds(\n",
    "    model: InfluenceMLP,\n",
    "    G: nx.DiGraph,\n",
    "    degree_centrality: Dict[int,float],\n",
    "    base_prob: Dict[int, Dict[Tuple[int,int],float]],\n",
    "    k: int,\n",
    "    budget: List[int]\n",
    ") -> List[Set[int]]:\n",
    "    chosen    = [set() for _ in range(k)]\n",
    "    available = set(G.nodes())\n",
    "    for t in range(k):\n",
    "        for _ in range(budget[t]):\n",
    "            best_v, best_gain = None, -1e9\n",
    "            base_feat = extract_feature(chosen[t], degree_centrality, base_prob[t], G, t).unsqueeze(0)\n",
    "            base_pred = model(base_feat).item()\n",
    "            for v in available - chosen[t]:\n",
    "                feat = extract_feature(chosen[t]|{v}, degree_centrality, base_prob[t], G, t).unsqueeze(0)\n",
    "                gain = model(feat).item() - base_pred\n",
    "                if gain > best_gain:\n",
    "                    best_gain, best_v = gain, v\n",
    "            if best_v is None:\n",
    "                break\n",
    "            chosen[t].add(best_v)\n",
    "            available.remove(best_v)\n",
    "    return chosen\n",
    "\n",
    "\n",
    "# --- 5. Main flow ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 5.1 Load dữ liệu bạn đã sinh ra\n",
    "    generated_file = \"output.txt\"\n",
    "    n, m, k, edges, loaded_probs, G = load_generated_data(generated_file)\n",
    "\n",
    "    # 5.2 Chuẩn base_prob: Dict[topic]→dict[(u,v)]→p0\n",
    "    base_prob: Dict[int, Dict[Tuple[int,int],float]] = {t:{} for t in range(k)}\n",
    "    for (u,v), p_list in loaded_probs.items():\n",
    "        for t in range(k):\n",
    "            base_prob[t][(u,v)] = p_list[t]\n",
    "\n",
    "    # 5.3 Khởi IC và centrality\n",
    "    ic    = MultiTopicIC(G, k, base_prob, sigma=0.05)\n",
    "    deg_c = nx.degree_centrality(G)\n",
    "\n",
    "    # 5.4 Tạo samples, targets\n",
    "    budget  = [5]*k\n",
    "    samples = []\n",
    "    targets = []\n",
    "    for t in range(k):\n",
    "        for _ in range(300):\n",
    "            S = set(random.sample(list(G.nodes()), budget[t]))\n",
    "            # chỉ tính spread cho topic t\n",
    "            spreads = ic.expected_spread([S if i==t else set() for i in range(k)], runs=30)\n",
    "            feat = extract_feature(S, deg_c, base_prob[t], G, t)\n",
    "            samples.append(feat)\n",
    "            targets.append(spreads[t])\n",
    "\n",
    "    X = torch.stack(samples)           # [N,4]\n",
    "    y = torch.tensor(targets)          # [N]\n",
    "    ds = TensorDataset(X, y)\n",
    "    loader = DataLoader(ds, batch_size=64, shuffle=True)\n",
    "\n",
    "    # 5.5 Train MLP\n",
    "    model = InfluenceMLP(input_dim=4, hidden_dims=[64, 32, 16])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn   = nn.MSELoss()\n",
    "    for epoch in range(25):\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*xb.size(0)\n",
    "        print(f\"Epoch {epoch+1:02d}  Loss = {total_loss/len(ds):.4f}\")\n",
    "\n",
    "    # 5.6 Tìm và đánh giá seed set tối ưu\n",
    "    optimal = search_optimal_seeds(model, G, deg_c, base_prob, k, budget)\n",
    "    print(\"Optimal seeds per topic:\", optimal)\n",
    "    final_spread = ic.expected_spread(optimal, runs=100)\n",
    "    print(\"Final expected spread:\", final_spread)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99eaee7edab82b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:38:32.958095Z",
     "start_time": "2025-05-23T20:38:32.954669Z"
    }
   },
   "source": [
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
