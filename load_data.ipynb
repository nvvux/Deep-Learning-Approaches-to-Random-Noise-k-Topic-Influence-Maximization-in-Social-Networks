{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T19:33:20.041947Z",
     "start_time": "2025-05-23T19:33:19.795373Z"
    }
   },
   "source": [
    "import networkx as nx\n",
    "\n",
    "def load_facebook_graph(path=\"facebook\"):\n",
    "    G = nx.Graph()\n",
    "    with open(path, \"r\") as f:\n",
    "        # Đọc dòng đầu: có hai số (số nút, số cạnh×2)\n",
    "        header = f.readline().strip().split()\n",
    "        # Nếu đúng là hai số, ta bỏ qua; còn nếu không phải thì dùng nó làm cạnh\n",
    "        if len(header) == 2 and header[0].isdigit() and header[1].isdigit():\n",
    "            n_nodes, twice_edges = map(int, header)\n",
    "        else:\n",
    "            # coi là dòng cạnh đầu\n",
    "            u, v = map(int, header)\n",
    "            G.add_edge(u, v)\n",
    "\n",
    "        # Đọc phần còn lại, mỗi dòng một cạnh u v\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            u, v = map(int, parts[:2])\n",
    "            G.add_edge(u, v)\n",
    "    return G\n",
    "\n",
    "# Ví dụ chạy ngay\n",
    "G = load_facebook_graph(\"facebook\")\n",
    "print(f\"Số nút: {G.number_of_nodes():,}  |  Số cạnh: {G.number_of_edges():,}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số nút: 4,039  |  Số cạnh: 88,234\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T19:31:01.544953Z",
     "start_time": "2025-05-23T19:29:59.699512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install networkx torch torchvision torchaudio\n"
   ],
   "id": "d6f4323311b9c03b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/212.5 MB 8.3 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 1.8/212.5 MB 8.4 MB/s eta 0:00:26\n",
      "    --------------------------------------- 3.7/212.5 MB 7.0 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 5.5/212.5 MB 7.8 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 7.3/212.5 MB 8.1 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 9.2/212.5 MB 8.3 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 11.3/212.5 MB 8.5 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 13.1/212.5 MB 8.7 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 15.2/212.5 MB 8.8 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 17.0/212.5 MB 8.9 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 19.1/212.5 MB 9.0 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 21.2/212.5 MB 9.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 23.3/212.5 MB 9.2 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 25.4/212.5 MB 9.3 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 27.5/212.5 MB 9.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 29.6/212.5 MB 9.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 31.7/212.5 MB 9.5 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 33.8/212.5 MB 9.5 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 35.9/212.5 MB 9.6 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 38.0/212.5 MB 9.7 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 40.1/212.5 MB 9.7 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 42.2/212.5 MB 9.7 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 44.3/212.5 MB 9.8 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 46.4/212.5 MB 9.8 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 48.5/212.5 MB 9.8 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 50.6/212.5 MB 9.9 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 53.0/212.5 MB 9.9 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 55.1/212.5 MB 9.9 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 57.1/212.5 MB 9.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 59.2/212.5 MB 10.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 61.3/212.5 MB 10.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 63.4/212.5 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 65.5/212.5 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 67.9/212.5 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 70.0/212.5 MB 10.1 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 72.1/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 74.4/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 76.5/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 78.6/212.5 MB 10.1 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 81.0/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 83.1/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 85.5/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 87.6/212.5 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 89.9/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 92.3/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 94.4/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 96.7/212.5 MB 10.3 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 99.1/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 101.4/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 103.8/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 106.2/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 108.0/212.5 MB 10.4 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 109.8/212.5 MB 10.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 111.4/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 113.2/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 115.3/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 117.2/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 119.3/212.5 MB 10.3 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 121.1/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 123.2/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 125.3/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 127.1/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 129.2/212.5 MB 10.3 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 131.6/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 133.7/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 136.1/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 138.1/212.5 MB 10.3 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 140.5/212.5 MB 10.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 142.9/212.5 MB 10.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 145.0/212.5 MB 10.3 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 147.3/212.5 MB 10.4 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 149.7/212.5 MB 10.4 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 152.0/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 154.4/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 156.8/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 158.9/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 160.4/212.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 162.3/212.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 163.8/212.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 165.7/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 167.5/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 169.3/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 171.2/212.5 MB 10.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 173.0/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 175.1/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 176.9/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 178.8/212.5 MB 10.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 180.9/212.5 MB 10.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 182.7/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 184.8/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 186.6/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 188.7/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 190.8/212.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 192.7/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 194.8/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 196.9/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 198.7/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 200.8/212.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 202.9/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 205.0/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 206.8/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  208.9/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  210.8/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 8.9 MB/s eta 0:00:00\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.13.2\n",
      "\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "    Uninstalling sympy-1.13.2:\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ---------------------------------------- 4/4 [torchaudio]\n",
      "\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-23T19:33:25.696190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from typing import Dict, List, Set, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# --- Multi-Topic Independent Cascade Simulation ---\n",
    "class MultiTopicIC:\n",
    "    def __init__(self, G: nx.DiGraph, k: int,\n",
    "                 prob: Dict[int, Dict[Tuple[int, int], float]]):\n",
    "        self.G = G\n",
    "        self.k = k\n",
    "        self.prob = prob\n",
    "\n",
    "    def simulate(self, seeds: List[Set[int]]) -> List[Set[int]]:\n",
    "        activated = [set(S) for S in seeds]\n",
    "        frontier = [set(S) for S in seeds]\n",
    "        while any(frontier):\n",
    "            new_frontier = [set() for _ in range(self.k)]\n",
    "            for i in range(self.k):\n",
    "                for u in frontier[i]:\n",
    "                    for v in self.G.successors(u):\n",
    "                        if v not in activated[i] and random.random() <= self.prob[i].get((u, v), 0.0):\n",
    "                            new_frontier[i].add(v)\n",
    "                            activated[i].add(v)\n",
    "            frontier = new_frontier\n",
    "        return activated\n",
    "\n",
    "    def expected_spread(self, seeds: List[Set[int]], runs: int = 100) -> List[float]:\n",
    "        total = [0.0] * self.k\n",
    "        for _ in range(runs):\n",
    "            act = self.simulate(seeds)\n",
    "            for i in range(self.k):\n",
    "                total[i] += len(act[i])\n",
    "        return [t / runs for t in total]\n",
    "\n",
    "# --- Probability Generator ---\n",
    "def generate_probabilities(G: nx.DiGraph, k: int, sigma: float = 0.1) -> Dict[int, Dict[Tuple[int, int], float]]:\n",
    "    indeg = {v: G.in_degree(v) if G.in_degree(v) > 0 else 1 for v in G.nodes()}\n",
    "    probs: Dict[int, Dict[Tuple[int, int], float]] = {i: {} for i in range(k)}\n",
    "    for i in range(k):\n",
    "        for u, v in G.edges():\n",
    "            base_p = 1.0 / indeg[v]\n",
    "            noise = random.gauss(0, sigma)\n",
    "            p = min(max(base_p + noise, 0.0), 1.0)\n",
    "            probs[i][(u, v)] = p\n",
    "    return probs\n",
    "\n",
    "# --- MLP Model for Influence Prediction ---\n",
    "class InfluenceMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int] = [64, 32]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "# --- Feature Extraction ---\n",
    "def extract_features(seed_set: Set[int], degree_centrality: Dict[int, float], topic: int) -> torch.Tensor:\n",
    "    sum_deg = sum(degree_centrality.get(v, 0.0) for v in seed_set)\n",
    "    size = len(seed_set)\n",
    "    return torch.tensor([sum_deg, size, float(topic)], dtype=torch.float32)\n",
    "\n",
    "# --- Greedy Search for Optimal Seed Sets ---\n",
    "def search_optimal_seeds(model: InfluenceMLP,\n",
    "                         k: int,\n",
    "                         G: nx.DiGraph,\n",
    "                         degree_centrality: Dict[int, float],\n",
    "                         budget: List[int]) -> List[Set[int]]:\n",
    "    seeds = [set() for _ in range(k)]\n",
    "    nodes = set(G.nodes())\n",
    "    for i in range(k):\n",
    "        for _ in range(budget[i]):\n",
    "            best_node, best_gain = None, -float('inf')\n",
    "            current_feat = extract_features(seeds[i], degree_centrality, i)\n",
    "            current_pred = model(current_feat.unsqueeze(0))[0].item()\n",
    "            for v in nodes - seeds[i]:\n",
    "                feat = extract_features(seeds[i] | {v}, degree_centrality, i)\n",
    "                pred = model(feat.unsqueeze(0))[0].item()\n",
    "                gain = pred - current_pred\n",
    "                if gain > best_gain:\n",
    "                    best_gain, best_node = gain, v\n",
    "            if best_node is None:\n",
    "                break\n",
    "            seeds[i].add(best_node)\n",
    "    return seeds\n",
    "\n",
    "# --- Main Workflow ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Load graph\n",
    "    path = \"facebook\"\n",
    "    G_undirected = nx.read_edgelist(path, nodetype=int)\n",
    "    G = G_undirected.to_directed()\n",
    "\n",
    "    # Generate topic-specific probabilities\n",
    "    k = 2\n",
    "    sigma_noise = 0.1\n",
    "    prob = generate_probabilities(G, k, sigma_noise)\n",
    "    ic_model = MultiTopicIC(G, k, prob)\n",
    "\n",
    "    # Precompute degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "    # Prepare training data by sampling random seed sets\n",
    "    budget = [2] * k  # number of seeds per topic\n",
    "    num_samples = 500\n",
    "    X_list, y_list = [], []\n",
    "    for topic in range(k):\n",
    "        for _ in range(num_samples):\n",
    "            S = set(random.sample(list(G.nodes()), budget[topic]))\n",
    "            feat = extract_features(S, degree_centrality, topic)\n",
    "            spread = ic_model.expected_spread([S if t == topic else set() for t in range(k)], runs=50)[topic]\n",
    "            X_list.append(feat)\n",
    "            y_list.append(spread)\n",
    "\n",
    "    # Build DataLoader\n",
    "    X = torch.stack(X_list)\n",
    "    y = torch.tensor(y_list, dtype=torch.float32)\n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Initialize and train MLP\n",
    "    model = InfluenceMLP(input_dim=3)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    epochs = 20\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataset):.4f}\")\n",
    "\n",
    "    # Find optimal seed sets using trained MLP\n",
    "    optimal_seeds = search_optimal_seeds(model, k, G, degree_centrality, budget)\n",
    "    print(\"Optimal seed sets:\", optimal_seeds)\n",
    "\n",
    "    # Compute predicted spread\n",
    "    spreads = [model(extract_features(optimal_seeds[i], degree_centrality, i).unsqueeze(0))[0].item() for i in range(k)]\n",
    "    total_spread = sum(spreads)\n",
    "    print(\"Predicted spread per topic:\", spreads)\n",
    "    print(\"Total predicted spread:\", total_spread)\n"
   ],
   "id": "5f170dc8d4000058",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
